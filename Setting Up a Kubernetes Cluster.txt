# Cloud Playground Settings

# Ubuntu 22.04 - Jammy Jellyfish, Medium (3 units), Tag = 'Kubernetes Master'
# Ubuntu 22.04 - Jammy Jellyfish, Small (2 units), Tag = 'Kubernetes Worker'

# Chapter 2.2 - 'Setting Up a Kubernetes Cluster'
# URL: https://learn.acloud.guru/course/97037e05-88ed-41a1-92ee-f5a8080318c2/learn/6507da5b-10a7-4c04-81d9-c3d58ad9c2d2/90cfb59d-c97b-44c3-b2ab-f9d1024ec4c1/watch

# In this lesson, you will setup your Kubernetes cluster. We will start by installing containerd.

# 1 - Installing containerd

# Here are the commands used install containerd. Run these on all servers.

# Distribution: Ubuntu 22.04 - Jammy Jellyfish
# Size: Small
# Tags: Kube Master, Kube Node

# Disable swap:

sudo swapoff -a

# Create configuration file for containerd:

cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF

# Load modules:

sudo modprobe overlay
sudo modprobe br_netfilter

# Set system configurations for Kubernetes networking:

cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF

# Apply new settings:

sudo sysctl --system

# Add Dockerâ€™s official GPG key:

sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
sudo chmod a+r /etc/apt/keyrings/docker.gpg

# Use the following command to set up the repository:

echo \
  "deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  "$(. /etc/os-release && echo "$VERSION_CODENAME")" stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Install containerd. Note: use the following command "sudo kill -9 $( sudo lsof /var/lib/dpkg/lock-frontend | awk '{ print $2 }' | tail -1 )" if you receive a "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it?" message.

sudo apt-get update && sudo apt-get install -y containerd

# Create default configuration file for containerd:

sudo mkdir -p /etc/containerd

# Generate default containerd configuration and save to the newly created default file:

sudo containerd config default | sudo tee /etc/containerd/config.toml

# Update the systemd cgroups parameter in the /etc/containerd/config.toml file:

sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml

# Restart containerd to ensure new configuration file usage:

sudo systemctl restart containerd

# Verify that containerd is running:

sudo systemctl status containerd

# 2 - Installing Kubeadm, Kubelet, and Kubectl

# Here are the commands used to install the Kubernetes components. Run these on all servers.

# Install dependency packages:

sudo apt-get update && sudo apt-get install -y apt-transport-https ca-certificates curl gpg software-properties-common

# Download and add GPG key:

sudo mkdir -p /etc/apt/keyrings && curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# Allow unprivileged APT programs to read this keyring

sudo chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# Add Kubernetes to repository list:

echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

# Helps tools such as command-not-found to work correctly

sudo chmod 644 /etc/apt/sources.list.d/kubernetes.list

# Update package listings:

sudo apt-get update

# Install Kubernetes packages. Note: use the following command "sudo kill -9 $( sudo lsof /var/lib/dpkg/lock-frontend | awk '{ print $2 }' | tail -1 )" if you receive a "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it?" message.

sudo apt-get install -y kubelet kubeadm kubectl

# Turn off automatic updates:

sudo apt-mark hold kubelet kubeadm kubectl

# Enable the kubelet service:

sudo systemctl enable --now kubelet

# 3 - Bootstrapping the Cluster

# On Kube Master and Kube Node, stop and disable ufw:

sudo systemctl stop ufw
sudo ufw disable

# On the Kube Master node, initialize the cluster:

sudo kubeadm init --pod-network-cidr 192.168.0.0/16

# Set kubectl access:

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# The kubeadm init command should output a kubeadm join command containing a token and hash. Copy that command and run it with sudo on both worker nodes. It should look something like this:

sudo kubeadm join $some_ip:6443 --token $some_token --discovery-token-ca-cert-hash $some_hash

# Use can print the full 'kubeadm join' flag needed to join the cluster with the following command:

kubeadm token create --print-join-command

# Run the kubeadm join command on your Kube Node server:

sudo kubeadm join <IP_ADDRESS> --token <TOKEN> --discovery-token-ca-cert-hash sha256:<HASH>

# From your Kube Master node, verify that all nodes have successfully joined the cluster:

kubectl get nodes

# You should see all three of your nodes listed. It should look something like this:

NAME                           STATUS     ROLES           AGE     VERSION
155f1d1c831c.mylabserver.com   NotReady   control-plane   2m21s   v1.30.3
155f1d1c832c.mylabserver.com   NotReady   <none>          37s     v1.30.3
155f1d1c833c.mylabserver.com   NotReady   <none>          12s     v1.30.3

# Note: The nodes are expected to have a STATUS of NotReady at this point

# 4 - Configuring Networking with Calico

# Install Calico in the cluster by running this only on the Master node:

kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml

# Verify that all the nodes now have a STATUS of "Ready":

kubectl get nodes

# You should see all three of your servers listed, and all should have a STATUS of "Ready". It should look something like this:

NAME                           STATUS   ROLES           AGE     VERSION
155f1d1c831c.mylabserver.com   Ready    control-plane   4m53s   v1.30.3
155f1d1c832c.mylabserver.com   Ready    <none>          3m9s    v1.30.3
155f1d1c833c.mylabserver.com   Ready    <none>          2m44s   v1.30.3

# Note: It may take a few moments for all nodes to enter the "Ready" status, so if they are not all "Ready", wait a few moments and try again.

# It is also a good idea to verify that the Calico pods are up and running. Run this command to get a list of system pods:

kubectl get pods -n kube-system

# Expected output:

NAME                                                   READY   STATUS    RESTARTS   AGE
calico-kube-controllers-5b9b456c66-2p9pn               1/1     Running   0          75s
calico-node-jff8p                                      1/1     Running   0          75s
calico-node-pwhfh                                      1/1     Running   0          75s
calico-node-zj79n                                      1/1     Running   0          75s
coredns-7db6d8ff4d-c48lp                               1/1     Running   0          5m5s
coredns-7db6d8ff4d-ct4fd                               1/1     Running   0          5m5s
etcd-155f1d1c831c.mylabserver.com                      1/1     Running   0          5m19s
kube-apiserver-155f1d1c831c.mylabserver.com            1/1     Running   0          5m19s
kube-controller-manager-155f1d1c831c.mylabserver.com   1/1     Running   0          5m19s
kube-proxy-ljbjf                                       1/1     Running   0          3m40s
kube-proxy-rsmwb                                       1/1     Running   0          3m15s
kube-proxy-rtnwg                                       1/1     Running   0          5m5s
kube-scheduler-155f1d1c831c.mylabserver.com            1/1     Running   0          5m19s

# You should have three pods with "calico" in the name, and all three should have a status of "Running".
